\documentclass{acm_proc_article-sp}

\usepackage{graphicx}


\usepackage{url}
\usepackage{hyperref} 
\hypersetup{breaklinks} 

\begin{document}
\title{LRT: The Live Remote Trace service for Mobile Debugging}
%\author{Cody Hanson, Ross Nordstrom\\
%        University of Colorado - Colorado Springs\\
%        \texttt{\{chanson,rnordstr\}@uccs.edu}
%       }
\date{June 2013}

\maketitle

\begin{abstract}
A concise and informative abstract will live here one day.
\end{abstract}

\section{Introduction}
One of the key tasks a mobile application developer must undertake is testing 
their application on real hardware, and with real users. This is important 
because there are many features that are available to apps running on hardware 
that are not available in emulation software. These include GPS, accelerometer, 
magnetometer, gyroscope, and Cellular data, as well as the rest of the 
complexity of the system that is impossible to recreate perfectly in an 
emulation layer. Real users and their environments also may exercise apps in
a way developers have not anticipated. 

We propose a system which will allow developers of applications on internet connected 
devices to easily embed lightweight instrumentation 
into their application code to enable high resolution 
tracing of program execution to a cloud service. Events are collected by 
the service which can perform analytics on program execution as it is 
exercised out in the wild.

Our research plan consists of prototyping a vertical slice of the system.
This includes the server infrastructure which will recieve trace data,
a background service which runs on the mobile platform, and a sample
application which has instrumentation that can broadcast to the background service.
In addition to investigating technologies that would make this technique 
feasible, we also will attempt to observe the processing and data workloads
involved, to better be able to select technologies used in a production version.

Successful completion of this work will serve to accomplish a few key 
improvements for testing mobile applications. This instrumentation will provide 
the developer with a trace of the program running on actual hardware, not just 
an emulator, as the opportunity to collect the trace while the application is 
subjected to real life users and environment interaction. With this 
body of program flow data collected on the server, we hypothesize that we can mine it for useful 
information to answer questions such as ``\emph{which parts of the user interface were 
confusing to the user?}'', and ``\emph{Did they spend too much time wondering what to do 
next?}'', or ``\emph{which flows are common for users to take, and could thus be 
streamlined to create a better user experience?}'' Problems of this nature are 
discussed in \cite{WebAntiPattern}.

In order for this work to be successful, we will need to 
prove out a few technical approaches. The first one will be to determine at what rate can we
export trace events from the application under test to the background LRT service 
before the user experience begins to degrade. 
We will also need to find out on what order of magnitude is the data
that we are collecting, and how that will impact the export-to-server performance.
Finally, we will attempt to write some simple queries against our database of
trace events, to gain some initial statistics and data that would give a developer
actionable information about the behavior of their application.

The remainder of this paper is organized as follows. Up front, we will cover 
related work in section \ref{section:relatedwork}. In section \ref{section:challenges},
we will discuss considerations that must be made when designing our system, and in 
\ref{section:proposeddesign} we will address these challenges with an outline of
our proposed design. In section \ref{section:crowdsourcing} we will discuss how to drive
user participation for crowdsourcing, which is a critical non-technical 
challenge to make our approach successful. The techniques to mine data for useful 
information are outlined in \ref{section:datamining}
Finally, we will discuss how we plan to evaluate our work in \ref{section:evaluation}.

\input{relatedwork}
\input{challenges}
\input{proposeddesign}
\input{crowdsource}
\input{datamining}
\input{evaluation}

\section{Conclusion}
...

\bibliography{citations}{}
\bibliographystyle{plain}

\end{document}

